<!DOCTYPE html>
<html>
<head>
<title>Azure Functions HOL (C#)</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
<style type="text/css">
.highlight  { background: #ffffff; }
.highlight .c { color: #999988; font-style: italic } /* Comment */
.highlight .err { color: #a61717; background-color: #e3d2d2 } /* Error */
.highlight .k { font-weight: bold } /* Keyword */
.highlight .o { font-weight: bold } /* Operator */
.highlight .cm { color: #999988; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #999999; font-weight: bold } /* Comment.Preproc */
.highlight .c1 { color: #999988; font-style: italic } /* Comment.Single */
.highlight .cs { color: #999999; font-weight: bold; font-style: italic } /* Comment.Special */
.highlight .gd { color: #000000; background-color: #ffdddd } /* Generic.Deleted */
.highlight .gd .x { color: #000000; background-color: #ffaaaa } /* Generic.Deleted.Specific */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #aa0000 } /* Generic.Error */
.highlight .gh { color: #999999 } /* Generic.Heading */
.highlight .gi { color: #000000; background-color: #ddffdd } /* Generic.Inserted */
.highlight .gi .x { color: #000000; background-color: #aaffaa } /* Generic.Inserted.Specific */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #555555 } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #aaaaaa } /* Generic.Subheading */
.highlight .gt { color: #aa0000 } /* Generic.Traceback */
.highlight .kc { font-weight: bold } /* Keyword.Constant */
.highlight .kd { font-weight: bold } /* Keyword.Declaration */
.highlight .kp { font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #445588; font-weight: bold } /* Keyword.Type */
.highlight .m { color: #009999 } /* Literal.Number */
.highlight .s { color: #d14 } /* Literal.String */
.highlight .na { color: #008080 } /* Name.Attribute */
.highlight .nb { color: #0086B3 } /* Name.Builtin */
.highlight .nc { color: #445588; font-weight: bold } /* Name.Class */
.highlight .no { color: #008080 } /* Name.Constant */
.highlight .ni { color: #800080 } /* Name.Entity */
.highlight .ne { color: #990000; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #990000; font-weight: bold } /* Name.Function */
.highlight .nn { color: #555555 } /* Name.Namespace */
.highlight .nt { color: #000080 } /* Name.Tag */
.highlight .nv { color: #008080 } /* Name.Variable */
.highlight .ow { font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mf { color: #009999 } /* Literal.Number.Float */
.highlight .mh { color: #009999 } /* Literal.Number.Hex */
.highlight .mi { color: #009999 } /* Literal.Number.Integer */
.highlight .mo { color: #009999 } /* Literal.Number.Oct */
.highlight .sb { color: #d14 } /* Literal.String.Backtick */
.highlight .sc { color: #d14 } /* Literal.String.Char */
.highlight .sd { color: #d14 } /* Literal.String.Doc */
.highlight .s2 { color: #d14 } /* Literal.String.Double */
.highlight .se { color: #d14 } /* Literal.String.Escape */
.highlight .sh { color: #d14 } /* Literal.String.Heredoc */
.highlight .si { color: #d14 } /* Literal.String.Interpol */
.highlight .sx { color: #d14 } /* Literal.String.Other */
.highlight .sr { color: #009926 } /* Literal.String.Regex */
.highlight .s1 { color: #d14 } /* Literal.String.Single */
.highlight .ss { color: #990073 } /* Literal.String.Symbol */
.highlight .bp { color: #999999 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #008080 } /* Name.Variable.Class */
.highlight .vg { color: #008080 } /* Name.Variable.Global */
.highlight .vi { color: #008080 } /* Name.Variable.Instance */
.highlight .il { color: #009999 } /* Literal.Number.Integer.Long */
.pl-c {
    color: #969896;
}

.pl-c1,.pl-mdh,.pl-mm,.pl-mp,.pl-mr,.pl-s1 .pl-v,.pl-s3,.pl-sc,.pl-sv {
    color: #0086b3;
}

.pl-e,.pl-en {
    color: #795da3;
}

.pl-s1 .pl-s2,.pl-smi,.pl-smp,.pl-stj,.pl-vo,.pl-vpf {
    color: #333;
}

.pl-ent {
    color: #63a35c;
}

.pl-k,.pl-s,.pl-st {
    color: #a71d5d;
}

.pl-pds,.pl-s1,.pl-s1 .pl-pse .pl-s2,.pl-sr,.pl-sr .pl-cce,.pl-sr .pl-sra,.pl-sr .pl-sre,.pl-src,.pl-v {
    color: #df5000;
}

.pl-id {
    color: #b52a1d;
}

.pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.pl-ml {
    color: #693a17;
}

.pl-mh,.pl-mh .pl-en,.pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.pl-mq {
    color: #008080;
}

.pl-mi {
    color: #333;
    font-style: italic;
}

.pl-mb {
    color: #333;
    font-weight: bold;
}

.pl-md,.pl-mdhf {
    background-color: #ffecec;
    color: #bd2c00;
}

.pl-mdht,.pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.pl-mo {
    color: #1d3e81;
}
.task-list {
padding-left:10px;
margin-bottom:0;
}

.task-list li {
    margin-left: 20px;
}

.task-list-item {
list-style-type:none;
padding-left:10px;
}

.task-list-item label {
font-weight:400;
}

.task-list-item.enabled label {
cursor:pointer;
}

.task-list-item+.task-list-item {
margin-top:3px;
}

.task-list-item-checkbox {
display:inline-block;
margin-left:-20px;
margin-right:3px;
vertical-align:1px;
}
</style>
</head>
<body>
<p><a name="HOLTitle"></a></p>
<h1 id="azure-functions">Azure Functions</h1>
<hr>
<p><a name="Overview"></a></p>
<h2 id="overview">Overview</h2>
<p>Functions have been the basic building blocks of software since the first lines of code were written and the need for code organization and reuse became a necessity. Azure Functions expand on these concepts by allowing developers to create &quot;serverless&quot;, event-driven functions that run in the cloud and can be shared across a wide variety of services and systems, uniformly managed, and easily scaled based on demand. In addition, Azure Functions can be written in a variety of languages, including C#, JavaScript, Python, Bash, and PowerShell, and they&#39;re perfect for building apps and nanoservices that employ a compute-on-demand model.</p>
<p>In this lab, you will create an Azure Function that monitors a blob container in Azure Storage for new images, and then performs automated analysis of the images using the Microsoft Cognitive Services <a href="https://www.microsoft.com/cognitive-services/en-us/computer-vision-api">Computer Vision API</a>. Specifically, The Azure Function will analyze each image that is uploaded to the container for adult or racy content and create a copy of the image in another container. Images that contain adult or racy content will be copied to one container, and images that do not contain adult or racy content will be copied to another. In addition, the scores returned by the Computer Vision API will be stored in blob metadata.</p>
<p><a name="Objectives"></a></p>
<h3 id="objectives">Objectives</h3>
<p>In this hands-on lab, you will learn how to:</p>
<ul>
<li>Create an Azure Function App</li><li>Write an Azure Function that uses a blob trigger</li><li>Add application settings to an Azure Function App</li><li>Use Microsoft Cognitive Services to analyze images and store the results in blob metadata</li></ul>
<p><a name="Prerequisites"></a></p>
<h3 id="prerequisites">Prerequisites</h3>
<p>The following are required to complete this hands-on lab:</p>
<ul>
<li>An active Microsoft Azure subscription. If you don&#39;t have one, <a href="http://aka.ms/WATK-FreeTrial">sign up for a free trial</a>.</li><li><a href="http://storageexplorer.com">Microsoft Azure Storage Explorer</a> (optional)</li></ul>
<p><a name="Resources"></a></p>
<h3 id="resources">Resources</h3>
<p><a href="https://a4r.blob.core.windows.net/public/functions-resources.zip">Click here</a> to download a zip file containing the resources used in this lab. Copy the contents of the zip file into a folder on your hard disk.</p>
<hr>
<p><a name="Exercises"></a></p>
<h2 id="exercises">Exercises</h2>
<p>This hands-on lab includes the following exercises:</p>
<ul>
<li><a href="#Exercise1">Exercise 1: Create an Azure Function App</a></li><li><a href="#Exercise2">Exercise 2: Add an Azure Function</a></li><li><a href="#Exercise3">Exercise 3: Add a subscription key to application settings</a></li><li><a href="#Exercise4">Exercise 4: Test the Azure Function</a></li><li><a href="#Exercise5">Exercise 5: View blob metadata (optional)</a></li></ul>
<p>Estimated time to complete this lab: <strong>45</strong> minutes.</p>
<p><a name="Exercise1"></a></p>
<h2 id="exercise-1-create-an-azure-function-app">Exercise 1: Create an Azure Function App</h2>
<p>The first step in writing an Azure Function is to create an Azure Function App. In this exercise, you will create an Azure Function App using the Azure Portal. Then you will add the three blob containers to the storage account that is created for the Function App: one to store uploaded images, a second to store images that do not contain adult or racy content, and a third to contain images that <em>do</em> contain adult or racy content.</p>
<ol>
<li><p>Open the <a href="https://portal.azure.com">Azure Portal</a> in your browser. If asked to log in, do so using your Microsoft account.</p>
</li><li><p>Click <strong>+ Create a resource</strong>, followed by <strong>Compute</strong> and <strong>Function App</strong>.</p>
<p> <img src="Images/new-function-app.png" alt="Creating an Azure Function App"></p>
<p> <em>Creating an Azure Function App</em></p>
</li><li><p>Enter an app name that is unique within Azure. Under <strong>Resource Group</strong>, select <strong>Create new</strong> and enter &quot;FunctionsLabResourceGroup&quot; (without quotation marks) as the resource-group name to create a resource group for the Function App. Choose the <strong>Location</strong> nearest you, and accept the default values for all other parameters. Then click <strong>Create</strong> to create a new Function App.</p>
<blockquote>
<p>The app name becomes part of a DNS name and therefore must be unique within Azure. Make sure a green check mark appears to the name indicating it is unique. You probably <strong>won&#39;t</strong> be able to use &quot;functionslab&quot; as the app name.</p>
</blockquote>
<p> <img src="Images/function-app-name.png" alt="Creating a Function App"></p>
<p> <em>Creating a Function App</em></p>
</li><li><p>Click <strong>Resource groups</strong> in the ribbon on the left side of the portal, and then click the resource group created for the Function App.</p>
<p> <img src="Images/open-resource-group.png" alt="Opening the resource group"></p>
<p> <em>Opening the resource group</em></p>
</li><li><p>Periodically click the <strong>Refresh</strong> button at the top of the blade until &quot;Deploying&quot; changes to &quot;Succeeded,&quot; indicating that the Function App has been deployed. Then click the storage account that was created for the Function App.</p>
<p> <img src="Images/open-storage-account.png" alt="Opening the storage account"></p>
<p> <em>Opening the storage account</em></p>
</li><li><p>Click <strong>Blobs</strong> to view the contents of blob storage.</p>
<p> <img src="Images/open-blob-storage.png" alt="Opening blob storage"></p>
<p> <em>Opening blob storage</em></p>
</li><li><p>Click <strong>+ Container</strong>. Type &quot;uploaded&quot; into the <strong>Name</strong> box and set <strong>Public access level</strong> to <strong>Private</strong>. Then click the <strong>OK</strong> button to create a new container.</p>
<p> <img src="Images/add-container.png" alt="Adding a container"></p>
<p> <em>Adding a container</em></p>
</li><li><p>Repeat Step 7 to add containers named &quot;accepted&quot; and &quot;rejected&quot; to blob storage.</p>
</li><li><p>Confirm that all three containers were added to blob storage.</p>
<p> <img src="Images/new-containers.png" alt="The new containers"></p>
<p> <em>The new containers</em></p>
</li></ol>
<p>The Azure Function App has been created and you have added three containers to the storage account created for it. The next step is to add an Azure Function.</p>
<p><a name="Exercise2"></a></p>
<h2 id="exercise-2-add-an-azure-function">Exercise 2: Add an Azure Function</h2>
<p>Once you have created an Azure Function App, you can add Azure Functions to it. In this exercise, you will add a function to the Function App you created in <a href="#Exercise1">Exercise 1</a> and write C# code that uses the <a href="https://www.microsoft.com/cognitive-services/en-us/computer-vision-api">Computer Vision API</a> to analyze images added to the &quot;uploaded&quot; container for adult or racy content.</p>
<ol>
<li><p>Return to the blade for the &quot;FunctionsLabResourceGroup&quot; resource group and click the Azure Function App that you created in <a href="#Exercise1">Exercise 1</a>. </p>
<p> <img src="Images/open-function-app.png" alt="Opening the Function App"></p>
<p> <em>Opening the Function App</em></p>
</li><li><p>Click the <strong>+</strong> sign to the right of <strong>Functions</strong>. Set the language to <strong>CSharp</strong>, and then click <strong>Custom function</strong>.</p>
<p> <img src="Images/add-function.png" alt="Adding a function"></p>
<p> <em>Adding a function</em></p>
</li><li><p>Set <strong>Language</strong> to <strong>C#</strong>. Then click <strong>BlobTrigger - C#</strong>.</p>
<p> <img src="Images/cs-select-template.png" alt="Selecting a function template"></p>
<p> <em>Selecting a function template</em></p>
</li><li><p>Enter &quot;BlobImageAnalysis&quot; (without quotation marks) for the function name and &quot;uploaded/{name}&quot; into the <strong>Path</strong> box. (The latter applies the blob storage trigger to the &quot;uploaded&quot; container that you created in Exercise 1.) Then click the <strong>Create</strong> button to create the Azure Function.</p>
<p> <img src="Images/create-azure-function.png" alt="Creating an Azure Function"></p>
<p> <em>Creating an Azure Function</em></p>
</li><li><p>Replace the code shown in the code editor with the following statements:</p>
<pre><code class="lang-C#"> using Microsoft.WindowsAzure.Storage.Blob;
 using Microsoft.WindowsAzure.Storage;
 using System.Net.Http.Headers;
 using System.Configuration;

 public async static Task Run(Stream myBlob, string name, TraceWriter log)
 {       
     log.Info($&quot;Analyzing uploaded image {name} for adult content...&quot;);

     var array = await ToByteArrayAsync(myBlob);
     var result = await AnalyzeImageAsync(array, log);

     log.Info(&quot;Is Adult: &quot; + result.adult.isAdultContent.ToString());
     log.Info(&quot;Adult Score: &quot; + result.adult.adultScore.ToString());
     log.Info(&quot;Is Racy: &quot; + result.adult.isRacyContent.ToString());
     log.Info(&quot;Racy Score: &quot; + result.adult.racyScore.ToString());

     if (result.adult.isAdultContent || result.adult.isRacyContent)
     {
         // Copy blob to the &quot;rejected&quot; container
         StoreBlobWithMetadata(myBlob, &quot;rejected&quot;, name, result, log);
     }
     else
     {
         // Copy blob to the &quot;accepted&quot; container
         StoreBlobWithMetadata(myBlob, &quot;accepted&quot;, name, result, log);
     }
 }

 private async static Task&lt;ImageAnalysisInfo&gt; AnalyzeImageAsync(byte[] bytes, TraceWriter log)
 {
     HttpClient client = new HttpClient();

     var key = ConfigurationManager.AppSettings[&quot;SubscriptionKey&quot;];
     client.DefaultRequestHeaders.Add(&quot;Ocp-Apim-Subscription-Key&quot;, key);

     HttpContent payload = new ByteArrayContent(bytes);
     payload.Headers.ContentType = new MediaTypeWithQualityHeaderValue(&quot;application/octet-stream&quot;);

     var endpoint = ConfigurationManager.AppSettings[&quot;VisionEndpoint&quot;];
     var results = await client.PostAsync(endpoint + &quot;/analyze?visualFeatures=Adult&quot;, payload);
     var result = await results.Content.ReadAsAsync&lt;ImageAnalysisInfo&gt;();
     return result;
 }

 // Writes a blob to a specified container and stores metadata with it
 private static void StoreBlobWithMetadata(Stream image, string containerName, string blobName, ImageAnalysisInfo info, TraceWriter log)
 {
     log.Info($&quot;Writing blob and metadata to {containerName} container...&quot;);

     var connection = ConfigurationManager.AppSettings[&quot;AzureWebJobsStorage&quot;].ToString();
     var account = CloudStorageAccount.Parse(connection);
     var client = account.CreateCloudBlobClient();
     var container = client.GetContainerReference(containerName);

     try
     {
         var blob = container.GetBlockBlobReference(blobName);

         if (blob != null) 
         {
             // Upload the blob
             blob.UploadFromStream(image);

             // Get the blob attributes
             blob.FetchAttributes();

             // Write the blob metadata
             blob.Metadata[&quot;isAdultContent&quot;] = info.adult.isAdultContent.ToString(); 
             blob.Metadata[&quot;adultScore&quot;] = info.adult.adultScore.ToString(&quot;P0&quot;).Replace(&quot; &quot;,&quot;&quot;); 
             blob.Metadata[&quot;isRacyContent&quot;] = info.adult.isRacyContent.ToString(); 
             blob.Metadata[&quot;racyScore&quot;] = info.adult.racyScore.ToString(&quot;P0&quot;).Replace(&quot; &quot;,&quot;&quot;); 

             // Save the blob metadata
             blob.SetMetadata();
         }
     }
     catch (Exception ex)
     {
         log.Info(ex.Message);
     }
 }

 // Converts a stream to a byte array
 private async static Task&lt;byte[]&gt; ToByteArrayAsync(Stream stream)
 {
     Int32 length = stream.Length &gt; Int32.MaxValue ? Int32.MaxValue : Convert.ToInt32(stream.Length);
     byte[] buffer = new Byte[length];
     await stream.ReadAsync(buffer, 0, length);
     stream.Position = 0;
     return buffer;
 }

 public class ImageAnalysisInfo
 {
     public Adult adult { get; set; }
     public string requestId { get; set; }
 }

 public class Adult
 {
     public bool isAdultContent { get; set; }
     public bool isRacyContent { get; set; }
     public float adultScore { get; set; }
     public float racyScore { get; set; }
 }
</code></pre>
<p> <code>Run</code> is the method called each time the function is executed. The <code>Run</code> method uses a helper method named <code>AnalyzeImageAsync</code> to pass each blob added to the &quot;uploaded&quot; container to the Computer Vision API for analysis. Then it calls a helper method named <code>StoreBlobWithMetadata</code> to create a copy of the blob in either the &quot;accepted&quot; container or the &quot;rejected&quot; container, depending on the scores returned by <code>AnalyzeImageAsync</code>. </p>
</li><li><p>Click the <strong>Save</strong> button at the top of the code editor to save your changes. Then click <strong>View files</strong>.</p>
<p> <img src="Images/cs-save-run-csx.png" alt="Saving the function"></p>
<p> <em>Saving the function</em></p>
</li><li><p>Click <strong>+ Add</strong> to add a new file, and name the file <strong>project.json</strong>.</p>
<p> <img src="Images/cs-add-project-file.png" alt="Adding a project file"></p>
<p> <em>Adding a project file</em></p>
</li><li><p>Add the following statements to <strong>project.json</strong>:</p>
<pre><code class="lang-json"> {
     &quot;frameworks&quot;: {
         &quot;net46&quot;: {
             &quot;dependencies&quot;: {
                 &quot;WindowsAzure.Storage&quot;: &quot;7.2.0&quot;
             }
         }
     }
 }
</code></pre>
</li><li><p>Click the <strong>Save</strong> button to save your changes. Then click <strong>run.csx</strong> to go back to that file in the code editor.</p>
<p> <img src="Images/cs-save-project-file.png" alt="Saving the project file"></p>
<p> <em>Saving the project file</em></p>
</li></ol>
<p>An Azure Function written in C# has been created, complete with a JSON project file containing information regarding project dependencies. The next step is to add an application setting that the Azure Function relies on.</p>
<p><a name="Exercise3"></a></p>
<h2 id="exercise-3-add-a-subscription-key-to-application-settings">Exercise 3: Add a subscription key to application settings</h2>
<p>The Azure Function you created in <a href="#Exercise2">Exercise 2</a> loads a subscription key for the Microsoft Cognitive Services Computer Vision API from application settings. This key is required in order for your code to call the Computer Vision API, and is transmitted in an HTTP header in each call. It also loads the base URL for the Computer Vision API (which varies by data center) from application settings. In this exercise, you will subscribe to the Computer Vision API, and then add an access key and a base URL to application settings.</p>
<ol>
<li><p>In the Azure Portal, click <strong>+ Create a resource</strong>, followed by <strong>AI + Cognitive Services</strong> and <strong>Computer Vision API</strong>.</p>
<p> <img src="Images/new-vision-api.png" alt="Creating a new Computer Vision API subscription"></p>
<p> <em>Creating a new Computer Vision API subscription</em></p>
</li><li><p>Enter &quot;VisionAPI&quot; into the <strong>Name</strong> box and select <strong>F0</strong> as the <strong>Pricing tier</strong>. Under <strong>Resource Group</strong>, select <strong>Use existing</strong> and select the &quot;FunctionsLabResourceGroup&quot; resource group that you created for the Function App in Exercise 1. Check the <strong>I confirm</strong> box, and then click <strong>Create</strong>.</p>
<p> <img src="Images/create-vision-api.png" alt="Subcribing to the Computer Vision API"></p>
<p> <em>Subcribing to the Computer Vision API</em></p>
</li><li><p>Return to the blade for &quot;FunctionsLabResourceGroup&quot; and click the Computer Vision API subscription that you just created.</p>
<p> <img src="Images/open-vision-api.png" alt="Opening the Computer Vision API subscription"></p>
<p> <em>Opening the Computer Vision API subscription</em></p>
</li><li><p>Copy the URL under <strong>Endpoint</strong> into your favorite text editor so you can easily retrieve it in a moment. Then click <strong>Show access keys</strong>.</p>
<p> <img src="Images/show-access-keys.png" alt="Viewing the access keys"></p>
<p> <em>Viewing the access keys</em></p>
</li><li><p>Click the <strong>Copy</strong> button to the right of <strong>KEY 1</strong> to copy the access key to the clipboard.</p>
<p> <img src="Images/copy-access-key.png" alt="Copying the access key"></p>
<p> <em>Copying the access key</em></p>
</li><li><p>Return to the Function App in the Azure Portal and click the app name in the ribbon on the left. Then click <strong>Application settings</strong>. </p>
<p> <img src="Images/open-app-settings.png" alt="Viewing application settings"></p>
<p> <em>Viewing application settings</em></p>
</li><li><p>Scroll down to the &quot;Application settings&quot; section. Add a new app setting named &quot;SubscriptionKey&quot; (without quotation marks), and paste the subscription key that is on the clipboard into the <strong>Value</strong> box. Then add a setting named &quot;VisionEndpoint&quot; and set its value to the endpoint URL you saved in Step 4. Finish up by clicking <strong>Save</strong> at the top of the blade.</p>
<p> <img src="Images/add-keys.png" alt="Adding application settings"></p>
<p> <em>Adding application settings</em></p>
</li><li><p>The app settings are now configured for your Azure Function. It&#39;s a good idea to validate those settings by running the function and ensuring that it compiles without errors. Click <strong>BlobImageAnalysis</strong>. Then click <strong>Run</strong> to compile and run the function. Confirm that no compilation errors appear in the output log, and ignore any exceptions that are reported.</p>
<p> <img src="Images/cs-run-function.png" alt="Compiling the function"></p>
<p> <em>Compiling the function</em></p>
</li></ol>
<p>The work of writing and configuring the Azure Function is complete. Now comes the fun part: testing it out.</p>
<p><a name="Exercise4"></a></p>
<h2 id="exercise-4-test-the-azure-function">Exercise 4: Test the Azure Function</h2>
<p>Your function is configured to listen for changes to the blob container named &quot;uploaded&quot; that you created in <a href="#Exercise1">Exercise 1</a>. Each time an image appears in the container, the function executes and passes the image to the Computer Vision API for analysis. To test the function, you simply upload images to the container. In this exercise, you will use the Azure Portal to upload images to the &quot;uploaded&quot; container and verify that copies of the images are placed in the &quot;accepted&quot; and &quot;rejected&quot; containers.</p>
<ol>
<li><p>In the Azure Portal, go to the resource group created for your Function App. Then click the storage account that was created for it.</p>
<p> <img src="Images/open-storage-account-2.png" alt="Opening the storage account"></p>
<p> <em>Opening the storage account</em></p>
</li><li><p>Click <strong>Blobs</strong> to view the contents of blob storage.</p>
<p> <img src="Images/open-blob-storage.png" alt="Opening blob storage"></p>
<p> <em>Opening blob storage</em></p>
</li><li><p>Click <strong>uploaded</strong> to open the &quot;uploaded&quot; container.</p>
<p> <img src="Images/open-uploaded-container.png" alt="Opening the &quot;uploaded&quot; container"></p>
<p> <em>Opening the &quot;uploaded&quot; container</em></p>
</li><li><p>Click <strong>Upload</strong>.</p>
<p> <img src="Images/upload-images-1.png" alt="Uploading images to the &quot;uploaded&quot; container"></p>
<p> <em>Uploading images to the &quot;uploaded&quot; container</em></p>
</li><li><p>Click the button with the folder icon to the right of the <strong>Files</strong> box. Select all of the files in this lab&#39;s &quot;Resources&quot; folder. Then click the <strong>Upload</strong> button to upload the files to the &quot;uploaded&quot; container.</p>
<p> <img src="Images/upload-images-2.png" alt="Uploading images to the &quot;uploaded&quot; container"></p>
<p> <em>Uploading images to the &quot;uploaded&quot; container</em></p>
</li><li><p>Return to the blade for the &quot;uploaded&quot; container and verify that eight images were uploaded.</p>
<p> <img src="Images/uploaded-images.png" alt="Images uploaded to the &quot;uploaded&quot; container"></p>
<p> <em>Images uploaded to the &quot;uploaded&quot; container</em></p>
</li><li><p>Close the blade for the &quot;uploaded&quot; container and open the &quot;accepted&quot; container.</p>
<p> <img src="Images/open-accepted-container.png" alt="Opening the &quot;accepted&quot; container"></p>
<p> <em>Opening the &quot;accepted&quot; container</em></p>
</li><li><p>Verify that the &quot;accepted&quot; container holds seven images. <strong>These are the images that were classified as neither adult nor racy by the Computer Vision API</strong>.</p>
<blockquote>
<p>Because you chose &quot;Consumption Plan&quot; when creating the Function App, it may take a few minutes for all of the images to appear in the container. If necessary, click <strong>Refresh</strong> periodically until you see all seven images.</p>
</blockquote>
<p> <img src="Images/accepted-images.png" alt="Images in the &quot;accepted&quot; container"></p>
<p> <em>Images in the &quot;accepted&quot; container</em></p>
</li><li><p>Close the blade for the &quot;accepted&quot; container and open the blade for the &quot;rejected&quot; container. Verify that the &quot;rejected&quot; container holds one image. <strong>This image was classified as adult or racy (or both) by the Computer Vision API</strong>.</p>
<p> <img src="Images/rejected-images.png" alt="Images in the &quot;rejected&quot; container"></p>
<p> <em>Images in the &quot;rejected&quot; container</em></p>
</li></ol>
<p>The presence of seven images in the &quot;accepted&quot; container and one in the &quot;rejected&quot; container is proof that your Azure Function executed each time an image was uploaded to the &quot;uploaded&quot; container. If you would like, return to the BlobImageAnalysis function in the portal and click <strong>Monitor</strong>. You will see a log detailing each time the function executed.</p>
<p><a name="Exercise5"></a></p>
<h2 id="exercise-5-view-blob-metadata-optional-">Exercise 5: View blob metadata (optional)</h2>
<p>What if you would like to view the scores for adult content and raciness returned by the Computer Vision API for each image uploaded to the &quot;uploaded&quot; container? The scores are stored in blob metadata for the images in the &quot;accepted&quot; and &quot;rejected&quot; containers, but blob metadata can&#39;t be viewed through the Azure Portal.</p>
<p>In this exercise, you will use the cross-platform <a href="http://storageexplorer.com">Microsoft Azure Storage Explorer</a> to view blob metadata and see how the Computer Vision API scored the images you uploaded.</p>
<ol>
<li><p>If you haven&#39;t installed the Microsoft Azure Storage Explorer, go to <a href="http://storageexplorer.com">http://storageexplorer.com</a> and install it now. Versions are available for Windows, macOS, and Linux.</p>
</li><li><p>Start Storage Explorer. If you are asked to log in, do so using the same account you used to log in to the Azure Portal.</p>
</li><li><p>Find the storage account that was created for your Azure Function App in <a href="#Exercise1">Exercise 1</a> and expand the list of blob containers underneath it. Then click the container named &quot;rejected.&quot;</p>
<p> <img src="Images/explorer-open-rejected-container.png" alt="Opening the &quot;rejected&quot; container"></p>
<p> <em>Opening the &quot;rejected&quot; container</em></p>
</li><li><p>Right-click (on a Mac, Command-click) the image in the &quot;rejected&quot; container and select <strong>Properties</strong> from the context menu.</p>
<p> <img src="Images/explorer-view-blob-metadata.png" alt="Viewing blob metadata"></p>
<p> <em>Viewing blob metadata</em></p>
</li><li><p>Inspect the blob&#39;s metadata. <em>IsAdultContent</em> and <em>isRacyContent</em> are Boolean values that indicate whether the Computer Vision API detected adult or racy content in the image. <em>adultScore</em> and <em>racyScore</em> are the computed probabilities.</p>
<p> <img src="Images/explorer-metadata-values.png" alt="Scores returned by the Computer Vision API"></p>
<p> <em>Scores returned by the Computer Vision API</em></p>
</li><li><p>Open the &quot;accepted&quot; container and inspect the metadata for some of the blobs stored there. How do these metadata values differ from the ones attached to the blob in the &quot;rejected&quot; container?</p>
</li></ol>
<p>You can probably imagine how this might be used in the real world. Suppose you were building a photo-sharing site and wanted to prevent adult images from being stored. You could easily write an Azure Function that inspects each image that is uploaded and deletes it from storage if it contains adult content.</p>
<p><a name="Summary"></a></p>
<h2 id="summary">Summary</h2>
<p>In this hands-on lab you learned how to:</p>
<ul>
<li>Create an Azure Function App</li><li>Write an Azure Function that uses a blob trigger</li><li>Add application settings to an Azure Function App</li><li>Use Microsoft Cognitive Services to analyze images and store the results in blob metadata</li></ul>
<p>This is just one example of how you can leverage Azure Functions to automate repetitive tasks. Experiment with other Azure Function templates to learn more about Azure Functions and to identify additional ways in which they can aid your research or business.</p>
<hr>
<p>Copyright 2017 Microsoft Corporation. All rights reserved. Except where otherwise noted, these materials are licensed under the terms of the Apache License, Version 2.0. You may use it according to the license as is most appropriate for your project on a case-by-case basis. The terms of this license can be found in <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>.</p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
